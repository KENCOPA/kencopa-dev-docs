---
type: note
tags:
- ai/ref
- ai
---
> [!info] 必要なセクションを選択して使用してください！

# 📖 背景・なぜ今これを検討するのか

## スタートアップの成長フェーズにおけるテスト戦略の再考

私たちのプロダクトは現在seed期にあり、急速な成長と変化の中で開発を進めている。この状況下で、以下の理由からバックエンドのテスト戦略を根本的に見直す必要がある

- **開発速度とテスト品質のバランス**:
	- 限られたリソースで最大の価値を生み出すため、全ての層に対して画一的なユニットテストを実施することの費用対効果を再検討する必要がある
- **AIツールの台頭による開発パラダイムの変化**
	- GitHub Copilot、Cursor、ChatGPTなどのAIツールにより、コード生成の速度・品質が飛躍的に向上した。これに伴い、テストの重点を「手動でのコード品質担保」から「システム全体の振る舞いの検証」へシフトする必要性が高まっている
- **4層アーキテクチャ（DDD）における課題**
	- 各層でのテスト実装において、何を検証すべきか、どこまでテストすべきかの基準が不明確で、開発者間でばらつきが生じる可能性がある
- **技術的負債の蓄積防止**
	- 「とりあえずテストが通ればいい」という形骸化したテストが増えることで、将来的な保守性や拡張性に悪影響を与えるリスクがある

# 🔍 現状・今どうなっているか

## アーキテクチャとテストの現状

現在のシステムは、Presentation、Application、Domain、Infrastructureの4層アーキテクチャを採用しており、ドメイン駆動設計（DDD）の原則に従って実装されている。テストについては、各層でユニットテストを実施する方針を取っているが、実際の運用において以下に示すような様々な課題が発生している：

## 具体的な課題

1. **テスト基準の不明確さ**
   - 各層で何を検証すべきか、達成基準が言語化されていない
   - 開発者によってテストの粒度や網羅性にばらつきがある
   - 「通ればいい」という形骸化したテストが散見される

2. **テスト実装の負担**
   - インメモリDBの定義が煩雑で、開発速度を阻害
   - モック(InMemoryDB)・テストデータの作成・管理コストが高い

3. **テスト戦略の不在**
   - ユニットテスト、統合テスト、E2Eテストなど各種テストの境界が曖昧
   - どの層でどのレベルのテストを行うべきかの指針がない
   - システム全体の振る舞いを保証する仕組みが不十分
    - 例えば、updateした後に、実際のDBのデータが更新されているか

## 開発環境の変化

- **AIツールの活用**
    - Copilot、Cursor, Claude Codeによるコード生成が日常化
- **開発速度の向上**: 
    - 機能実装のスピードは向上したが、テスト作成がボトルネックに
- **品質保証の課題**
    - 自動生成されたコードの品質をどう担保するかが新たな課題に

# ❓ 検討したいポイント・悩んでいること

## テスト戦略の根本的な見直し

- [x]  **テストレベルの再定義について**:
    - ユニットテスト、統合テストの境界線をどう定義すべきか？
    - 各テストレベルで何を保証すべきか？

- [x]  **4層アーキテクチャにおけるテスト方針について**:
    - 全ての層でユニットテストは本当に必要か？
        - 例えばDomain層のみユニットテストを重視し、他層は統合テストで検証するなど
    - 各層のテスト完了基準をどう定めるべきか？

- [x]  **依存関係の扱いについて**:
    - プロセス外依存（DB、外部API等）をモックすべきか実体を使うべきか？
    - 共有依存とプライベート依存をどう区別し、テスト戦略に反映すべきか？
    - テスト用のDockerコンテナやLocalStackの活用方針は？

- [x]  **seed期スタートアップとしての優先順位について**:
    - 開発速度とテスト品質のバランスをどう取るべきか？
    - 最小限のテストで最大の品質保証を得るには？
    - 技術的負債を避けつつ、過度なテストを回避する方法は？

- [ ]  ~~AIツール時代のテスト戦略について~~: -> 今後検討したい
    - 自動生成コードの品質をどう担保すべきか？
    - テスト自動生成の活用と限界は？
    - 人間が注力すべきテスト領域はどこか？

- [x]  **実装と運用について**:
    - テスト環境のセットアップをどう簡素化すべきか？
    - CI/CDパイプラインでのテスト実行戦略は？
    - テストの実行時間とカバレッジのトレードオフをどう管理すべきか？

# 🎯 期待する結果・どんな意見がほしいか

- [x]  **ブレインストーミング**: アイデアや選択肢を広げたい
- [x]  **技術的なアドバイス**: 経验や知識に基づく助言がほしい
- [x]  **リスク評価**: 潜在的な問題や注意点を教えてほしい
- [x]  **方向性の決定**: どの方向に進むべきか決めたい
- [x]  **実装方法の相談**: 具体的な実装手法について相談したい
- [ ]  **優先度の判断**: 重要度や緊急度について意見がほしい
- [ ]  **情報収集**: 関連する情報や事例を知りたい
- [ ]  **その他**: [具体的に何を期待しているか]

#  UT/ITの定義・境界線の認識合わせ

[[💭 ソフトウェアテスト戦略に関する仮説検証：ユニットテストから統合テストまでのリサーチ]]にて、UTとITの定義と境界を整理した。
(※全体に目を通すとわかりやすいです)

要約：
- UT/ITの定義
	- [[💭 ソフトウェアテスト戦略に関する仮説検証：ユニットテストから統合テストまでのリサーチ#ソフトウェアテストの基本概念]]
- 統合テストとユニットテストの境界
	- [[💭 ソフトウェアテスト戦略に関する仮説検証：ユニットテストから統合テストまでのリサーチ#統合テストとユニットテストの境界]]
		- UT/ITの境界として扱われるモジュールテストについて焦点を当てた

# バックエンドのテスト方針について

**概要**: 

業務の中核、およびセキュリティ的に重要なコードのみUTを実施し、それ以外はITaとしてシステムの振る舞いを検証する。

**Seed期スタートアップとしての戦略的判断**:

なぜこの方針なのか：
- **限られたリソースの最適配分**: エンジニアの時間を最もビジネス価値の高いテストに集中
- **素早いイテレーション**: PR作成を妨げない高速なフィードバックループ -> [[💭 BEのユニットテスト方針について#CI/CDパイプライン戦略]]を参照
- **実ユーザー体験の検証**: エンドポイントからのテストで、実際のユーザーシナリオを確実に保証
- **開発体験の最適化**: 待ち時間を最小化し、開発者の集中を維持

**具体的な実装方針**：

- Domain層やAuthorization層、また共通関数的な層に対してのみ、そのコンポーネントのみに焦点を当てたUTを実施する
    - **投資対効果**: これらの層のバグは致命的（ビジネスロジック誤り、セキュリティホール）
    - これら対象が使用しているその他モジュールや、プロセス外依存については、(TestFWで利用可能な)Mockを使用する
    - **目標実装時間**: 1機能あたり30分以内でUT作成
    
- それ以外は、endpointを起点にした統合テストを実施する
    - **メリット**: 1つのテストで複数層をカバー、実装変更に強い(vs regression)
    - プロセス外依存 & プライベート依存については、環境構築が容易なもののみ実際の依存関係（Docker, DB, localstackを含む)を使用する
    - それ以外は、スタブやMockなどを使用する
        - ex) SESのメール送信クラスは、テスト時にはメール送信を行わず、メール送信の成功/失敗をテストできるようにStubを使用する、など
    - **目標実装時間**: 1エンドポイントあたり1時間以内でテスト作成

**期待される成果**：
- テスト作成時間を従来の1/3に短縮
- カバレッジ80%以上を維持しつつ、重要部分に集中
- 仕様変更時のテスト修正工数を最小化

**メリット**:
- Domain層＋Authorization層のユニットテスト集中
  - ビジネスロジックの核心部分に集中する戦略は理にかなっている
  - Authorizationは特に重要で、セキュリティホールを防ぐために必須
- それ以外の層への統合テストアプローチ
  - HTTPエンドポイントでのreq/res検証は、実際のユーザー体験に直結
  - その他層の複雑なセットアップを避けられる
- カバレッジメトリクスでの補完
  - 他のコードも実際に実行されることを確認する現実的なアプローチ

**考慮すべき点**:
- Application層/Infra層のテスト不足リスク
  - -> 複雑な業務フローやエラーハンドリングが見落とされる可能性はあるが、統合テスト的アプローチできる（されるべき）

refs:
- https://zenn.dev/ignorant_kenji/articles/6f740feabf6f30#%E3%81%AA%E3%81%9C%E3%80%81%E7%B5%B1%E5%90%88%E3%83%86%E3%82%B9%E3%83%88%E3%81%AF%E9%87%8D%E8%A6%81%E3%81%AA%E3%81%AE%E3%81%A0%E3%82%8D%E3%81%86%E3%81%8B
> 統合テストの大きな価値の一つは、E2Eテストと同じようにユーザーのふるまいをテストできることにあります。
> ユーザーがコンポーネントを単体で使用することはほとんどなく、ほとんどのWebアプリは、異なるコンポーネント間の相互作用として実行されます。
> このため、統合テストは、特定のロジックの入力と出力をテストするだけの単体テストと比べて、テスト結果の信頼性が高くなると思います。
> なので、最初に書くべきなのは統合テストだと捉えています。 この考え方は、ほとんどの人は直感に反したり、異なる意見を持っているかもしれません。
> 開発サイクルの中で不具合を発見するのが遅ければ遅いほど、その修正にかかる費用は高くなると教えられてきました。統合テストなどの「大きなタスク」に着手する前に、すべての細部を完璧にしようとします。
> 先に単体テストを書いていては必要なビジネスロジックを柔軟に変更しながら開発を進めることができません。
> ですが、統合テストをむやみに書けばいいとは限りません。良いテストの条件を満たすために戦略を練らなければならないからです。
![[スクリーンショット 2025-06-24 18.38.09.png]]

良いテストをするために、以下を検討したい。
# 統合テスト時(ITa)のプロセス外依存 & プライベート依存の扱いについて

**概要**:

- DBはこれまで通りリポジトリ内で定義したDockerを使用する
- S3などのAWSサービスについて、使用可能であればlocalstackを使用する
- それ以外は、スタブを使用する(実装の差し替え) => 共有依存扱い

**メリット**
- **本番に近い環境でのテスト**
  - Docker化されたDBは実際のDBエンジンを使用するため、本番環境に近い動作を確認可能
  - LocalStackによりAWSサービスの実際のAPIインターフェースをテスト
- **環境構築の標準化**
  - Dockerによる環境構築は再現性が高く、チーム全体で同じ環境を共有可能
  - LocalStackは多くのAWSサービスをカバーし、設定も比較的シンプル
- **実際のI/O操作の検証**
  - ファイル操作、ネットワーク通信、データベーストランザクションなど実際の動作を確認
  - SQLクエリの最適化やインデックスの効果も検証可能
- **プライベート依存の活用**
  - テストごとに独立した環境（別コンテナ、別DB）を用意することで並列実行可能
  - テスト間の干渉を防ぎながら、実環境に近いテストを実現

**デメリット**
- **セットアップの複雑性**
  - Docker ComposeやLocalStackの設定が必要
  - 初回セットアップに時間がかかる可能性
- **実行速度の低下**
  - コンテナの起動・停止に時間がかかる
  - 実際のI/O操作を行うため、モックより遅い
- **リソース使用量**
  - 複数のDockerコンテナを起動するため、メモリ・CPU使用量が増加
  - CI環境でのリソース制限に注意が必要
- **LocalStackの制限**
  - 全てのAWSサービスの機能が完全に実装されているわけではない
  - 一部の高度な機能はサポートされていない可能性

# 統合テスト時(ITa)のプロセス外依存 & 共有依存の扱いについて

**概要**:

共有依存を扱っているクラスについては、テスト時には実装の入れ替えを行う。

- 具体的に、各層はinterfaceにより依存関係を定義し、そのinterfaceを実装するクラスをテスト時にはStub化された実装に入れ替える
- Stub化された実装は、paramに応じて正常、異常を返すようにすると良い

**メリット**
- **テストの独立性確保**
  - 共有依存をStub化することで、他のテストやシステムの状態に影響されない
  - 並列実行が安全に行える
- **実行速度の向上**
  - 外部サービスへの実際の通信を避けることで高速化
  - CI/CDパイプラインでの実行時間短縮
- **コスト削減**
  - 従量課金サービス（SES、S3等）の利用料金が発生しない
  - テスト環境の維持コストを最小化
- **テストシナリオの制御**
  - パラメータに応じて正常系・異常系を自在に制御可能
  - エッジケースや障害シナリオを容易に再現
- **開発体験の向上**
  - ローカル環境でのテスト実行が容易
  - 外部サービスの認証情報設定が不要

**デメリット**
- **実装の追加作業**
  - Interface定義とStub実装の作成が必要
  - 本番実装とStub実装の両方をメンテナンスする必要
    - -> 各APIのrouteで分岐を実装するのではなく、`Registry`クラスを用意して、そこで分岐を実装すると良いかも(一元管理)
    - -> DIコンテナライブラリとか入れる？(nodejsはこの辺り若干微妙で、前職では採用を見送った)、設定ファイルを作るなどもあり
    - -> 一元管理しておけば、Unit Testをしやすい（`env = test`のみ、stubになっている)
- **実環境との乖離リスク**
  - Stubが実際のサービスの振る舞いを完全に再現できない可能性
  - 外部サービスの仕様変更に追従が必要
  -> これはITa以降のテストでカバーする想定
- **初期設計の複雑性**
  - 依存性注入の仕組みを適切に設計する必要
  - テスト用と本番用の実装切り替え機構が必要
  
Registryの実装例：
```typescript
 // Registryパターンの例
  class ServiceRegistry {
    static getEmailService(): IEmailService {
      return process.env.NODE_ENV === 'test'
        ? new EmailServiceStub()
        : new SESService();
    }

    static getStorageService(): IStorageService {
      return process.env.NODE_ENV === 'test'
        ? new StorageServiceStub()
        : new S3Service();
    }
  }

  // APIルートはシンプルに
  app.post('/send-notification', async (req, res) => {
    const emailService = ServiceRegistry.getEmailService();
    await emailService.send(req.body);
  });
```

DIコンテナの活用
```typescript
  container.register('EmailService', {
    useClass: process.env.NODE_ENV === 'test'
      ? EmailServiceStub
      : SESService
  });
```
設定の外部化
```typescript
  export const serviceConfig = {
    test: {
      emailService: EmailServiceStub,
      storageService: StorageServiceStub
    },
    production: {
      emailService: SESService,
      storageService: S3Service
    }
  };
```

# CI/CDパイプライン戦略

**概要**：

テストの実行タイミングを戦略的に分離し、開発速度と品質保証のバランスを最適化する。

**実行タイミングの最適化**：
- **PR時**: UTのみ実行（高速フィードバック、5分以内）
  - Domain層、Authorization層、共通関数のテストのみ
  - ビルドエラーや基本的なロジックエラーを即座に検出
- **マージ時(または定期実行：一日一回など)**: ITa実行（完全な検証、結果はSlack通知）
  - エンドポイントからの統合テスト全体を実行
  - 実際のユーザーシナリオを完全に検証

**メリット**：
- **開発速度の向上**
  - PR作成・レビューが5分以内で完了
  - 開発者の待ち時間を最小化し、コンテキストスイッチを防止
- **段階的な機能開発の促進**
  - PR単位で完全な統合テストを書く必要がない
  - 例：ユーザー作成APIを実装しても、ユーザー一覧取得APIがまだない場合、統合テストは後から追加可能
  - 小さな機能を段階的にマージでき、大きなPRを避けられる
- **品質の担保**
  - マージ後に完全な統合テストを実行
  - 問題発生時は即座にSlack通知で全員が認識
- **効率的なリソース利用**
  - 重いITaテストはマージ後に非同期実行
  - CI/CDのコンピューティングリソースを効率的に活用
- **心理的安全性**
  - ITaのセットアップ失敗による影響をUTは受けない
  - PRの作成が軽量になり、小さな変更を頻繁にマージ可能
  - 統合テストの完璧さを求められないため、開発者のプレッシャーが軽減
  - 失敗しても即座に通知されるため、迅速な対応が可能

**デメリットと対策**：
- **マージ後の問題発見**
  - 対策: Slack通知による即座の認識
- **ITaの実行時間**
  - 対策: 並列実行やテストの優先順位付けで最適化

**実装例**：
```yaml
# .github/workflows/pr.yml
on: pull_request
jobs:
  unit-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - run: npm test:unit

# .github/workflows/merge.yml  
on:
  push:
    branches: [main]
jobs:
  integration-tests:
    runs-on: ubuntu-latest-4core
    timeout-minutes: 30
    steps:
      - run: npm test:integration
      - uses: slack-notification-action
        if: failure()
```

[まだ考えていない選択肢があれば、コメントで教えてください]

# 🔗 関連情報・参考資料

[参考になる情報があれば記載してください]

- **関連するADR**:
- **関連するDesign Doc**:
- **関連するLinearタスク**:
- **参考記事・ドキュメント**:
    - 
- **過去の似たような議論**: [リンク]
- **関連するシステム・サービス**: [名前とリンク]

---

# 💬 ディスカッション・コメント

[この下にコメントが追加されます]

# 📝 検討過程メモ

[検討中に気づいたことや、議論の流れをメモしてください]

# ✅ 結論・決定事項（検討完了後に記載）

[検討が完了したら、ここに結論を記載してください]

## 決定内容

[何が決まったのか]

## 決定理由

[なぜその決定に至ったのか]

## 反対意見・懸念事項

[決定に対する懸念や反対意見があれば記載]

## 次のアクション

- [ ]  [具体的なアクション1]
- [ ]  [具体的なアクション2]
- [ ]  ADR作成の必要性
- [ ]  Design Doc作成の必要性
- [ ]  Linearタスク作成: [タスクへのリンク]

 
