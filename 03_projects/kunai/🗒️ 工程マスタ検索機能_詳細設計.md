---
type: note
tags:
moc:
下書き: false
提案済み:
承認済み:
代替済み:
非推奨:
棄却:
---
### 1.1. 目的
表記揺れによって実質的に同じ内容の工程マスタが複数登録されるのを防ぐため、入力文字列に対して意味的に類似する工程マスタを候補として返すAPIを実装する。

### 1.2. 背景
従来のキーワード検索では、完全に一致する単語が含まれていないと目的のデータを発見できないという課題があった。ベクトル検索を導入することで、単語の表記揺れや類義語を吸収し、より文脈に沿った柔軟で精度の高い検索体験を提供することが可能になる。

## 2. アーキテクチャ

### 2.1. 全体構成
本機能は、既存のアーキテクチャに、ベクトルデータ生成のバッチ処理と、ベクトル検索APIフローを追加する形で実現される。

1. **データ生成 (バッチ)**: `generate_work_embeddings.py` スクリプトが `work_types` テーブルのテキストデータを取得し、`OpenAIEmbeddingAdapter` を通じてベクトル化。結果を `work_embeddings` テーブルに保存（INSERT/UPDATE）する。
2. **検索API**: クライアントからの検索リクエストを受け取ると、`search` エンドポイントが `SearchWorktreesUsecase` を呼び出す。Usecaseは `EmbeddingAdapter` でクエリをベクトル化し、`PrismaWorkTypeRepository` を通じてデータベースで類似度検索を実行する。
    

### 2.2. 使用技術スタック
- **データベース**: PostgreSQL
- **DB拡張機能**: `pgvector`
- **ORM**: Prisma
- **Embedding連携**: LangChain (`langchain-openai`)
- **Embeddingモデル**: OpenAI `text-embedding-3-small` (1536次元)
- **バックエンド**: Python, FastAPI
- **インフラ**: Docker
## 3. データベース設計

ベクトルデータを格納するため、新たに `work_embeddings` テーブルを追加し、既存の `work_types` テーブルと1対1の関係で紐付ける。

### 3テーブル定義 (Prismaスキーマ)

`prisma/schema.prisma` ファイルで、モデル間の関係を以下のように定義する。

#### `work_type` モデル

`work_embedding` への1対1リレーションを `embedding` フィールドで定義。

```
model work_type {
  id          String           @id @default(uuid())
  name        String
  description String?
  is_archived Boolean          @default(false)
  embeddings  work_embedding? // 1対1リレーション

  @@map("work_types")
}
```

#### `work_embedding` モデル 

`work_type_id` に `@unique` 制約を付与することで、1対1の関係をデータベースレベルで保証する。

```
model work_embedding {
  id           String                      @id @default(uuid())
  work_type_id String?                     @unique
  embedding    Unsupported("vector(1536)")
  createdAt    DateTime                    @default(now())
  updatedAt    DateTime                    @updatedAt
  work_type    work_type?                  @relation(fields: [work_type_id], references: [id])

  @@map("work_embeddings")
}
```
## 4. 機能仕様

### 4.1. ベクトルデータ生成・更新フロー（バッチ処理）
`work_types` のデータからベクトルを生成・管理するため、以下のスクリプト群を用意する。
1. **`setup_work_embeddings_table.py`**:
    - **役割**: `pgvector`拡張機能の有効化 (`CREATE EXTENSION IF NOT EXISTS vector;`) と `work_embeddings` テーブルの作成 (`CREATE TABLE`) を行う。環境構築の初期段階で実行する。
2. **`seed_work_types.py`**:
    - **役割**: `work_types` テーブルに開発用の初期データを投入する。
3. **`generate_work_embeddings.py`**:
    - **役割**: メインのベクトル生成スクリプト。`work_types` テーブルの全件を対象に、ベクトルが存在しない場合は新規作成（INSERT）、存在する場合は更新（UPDATE）する。定期的な実行を想定。
    - **処理内容**:
        1. 全`work_type`を取得。
        2. `work_type`ごとに`name`と`description`を結合したテキストを作成。
        3. `OpenAIEmbeddingAdapter` を使用してテキストを1536次元のベクトルに変換。
        4. `work_type_id`をキーに`work_embeddings`テーブルを検索し、既存データがあれば`UPDATE`、なければ`INSERT`を実行。
            
### 4.2. ベクトル検索APIフロー

APIエンドポイント `/api/ai/v1/protected/work_trees/search` は、リクエストボディの `use_vector_search` フラグによって挙動を切り替える。`false`なら部分検索する。
1. **リクエスト**: クライアントは検索クエリ(`query`)と`use_vector_search: true`を含むリクエストを送信。
2. **Usecase実行**: `search` エンドポイントが `SearchWorktreesUsecase` を呼び出す。
3. **クエリのベクトル化**: Usecaseは `EmbeddingAdapter` (`OpenAIEmbeddingAdapter`) を呼び出し、受け取った `query` 文字列をベクトルに変換する。
4. **類似度検索**: Usecaseは `WorkTypeRepository` (`PrismaWorkTypeRepository`) の `find_by_vector_similarity` メソッドにベクトルを渡して検索を実行する。
5. **DBクエリ実行**: Repositoryは、`pgvector`のコサイン距離演算子 (`<=>`) を使用した生のSQLクエリを実行し、類似度スコアの高い順に結果を取得する。
6. **レスポンス**: UsecaseはRepositoryから受け取った`VectorSearchResult`をレスポンス用の`WorkTypeResult`に変換し、クライアントに返却する。
    

## 5. 実装詳細
### 5.1. 主要コンポーネントの責務
- **`EmbeddingAdapterProtocol`**:
    - テキストをベクトルに変換する処理のインターフェースを定義する。「テキストを受け取り、floatのリストを返す」という契約を定める。
- **`OpenAIEmbeddingAdapter`**:
    - `EmbeddingAdapterProtocol`の具象クラス。LangChainの`OpenAIEmbeddings`を利用して、OpenAI APIとの通信を実際に行う。
- **`WorkTypeRepositoryProtocol`**:
    - `WorkType`のデータアクセス層のインターフェース。`find_by_vector_similarity`メソッドの仕様を定義する。
- **`PrismaWorkTypeRepository`**:
    - `WorkTypeRepositoryProtocol`の具象クラス。`find_by_vector_similarity`メソッド内で、後述の生のSQLクエリを実行し、結果を`VectorSearchResult`オブジェクトにマッピングする。
- **`SearchWorktreesUsecase`**:
    - ビジネスロジックの中核。`use_vector_search`フラグに基づき、`find_by_vector_similarity`（ベクトル検索）と`find_by_name_contains`（キーワード検索）のどちらを呼び出すかを決定するオーケストレーター。
        
### 5.2. 類似度検索クエリ
`PrismaWorkTypeRepository.find_by_vector_similarity` 内で実行されるSQLクエリは以下の通り。
```
SELECT
    wt.id,
    wt.name,
    wt.description,
    wt.is_archived,
    we.embedding::text,
    1 - (we.embedding <=> $1::vector) as similarity
FROM work_types wt
INNER JOIN work_embeddings we ON wt.id = we.work_type_id
ORDER BY we.embedding <=> $1::vector
LIMIT $2
```
- `$1`: 検索クエリから生成された1536次元のベクトル。
- `$2`: 取得したい件数 (`limit`)。
- `<=>`: `pgvector`が提供するコサイン距離を計算する演算子。値が0に近いほど類似度が高いため、`ORDER BY`句でそのまま使用し、`SELECT`句では`1 - distance`として「類似度スコア」に変換している。
- `we.embedding::text`: `work_embeddings`テーブルから埋め込みベクトルを取得し、テキスト形式にキャストしている。そのままだと保存されなかったためtext形式にしている。


## 6. アーキテクチャ決定記録 (ADR)

### ADR-1: Embeddingモデルの選定とAPI利用方法

- **コンテキスト**:
    - 本機能の中核となるEmbeddingモデルを選定する必要があった。
    - 複数のモデル提供サービス（OpenRouter, AWS Bedrock, OpenAI）が検討対象となった。
- **決定**:
    - EmbeddingモデルとしてOpenAIの `text-embedding-3-small` を採用する。
    - APIはプロキシサービス（OpenRouter等）を介さず、OpenAIの公式APIを直接利用する。
- **理由**:
    - **OpenRouterの制約**: 現時点でOpenRouterはLLMモデルへのAPIアクセスのみを提供しており、Embeddingモデルはサポート対象外だったため。
    - **開発環境の制約**: AWS Bedrockの `Titan Text Embedding` モデルも検討したが、開発環境で利用しているLocalStackの無料版ではサポートされていなかったため。
    - 上記の制約から、安定して利用可能かつ実績のあるOpenAI APIを直接利用することが最も合理的であると判断した。
### ADR-2: データベーススキーマ設計

- **コンテキスト**:
    - ベクトルデータをどのように格納するかについて、2つの選択肢があった。
        1. 既存の `work_types` テーブルに `embedding` カラムを追加する。
        2. 新たに `work_embeddings` テーブルを作成し、`work_types` と1対1で関連付ける。
- **決定**:
    - `work_embeddings` テーブルを `work_types` テーブルから分離する。
- **理由**:
    
    - **関心の分離**: ベクトルデータとその元となるマスタデータを分離することで、責務が明確になる。ベクトルの再生成や、将来的に異なる種類のベクトル（例：別モデルで生成したベクトル）を追加する際に、`work_types` テーブル本体に影響を与えない。
        
- **検討した代替案**:
    - `work_types` に `embedding` カラムを追加する案。
    - **デメリット**:
        - テーブルサイズが肥大化し、ベクトルが不要なクエリでもパフォーマンスに影響を与える可能性がある。
        - スキーマの関心が混在し、将来的なメンテナンス性が低下する懸念がある。

### ADR-3: 初期実装範囲の決定

- **コンテキスト**:
    - ベクトル検索機能をどのマスタデータから導入していくかを検討した。
- **決定**:
    - 初期実装では対象を `work_type`（工程マスタ）に限定する。
- **理由**:
    - **スモールスタート**: まずは一つのマスタに絞って導入することで、ベクトル検索の有効性を検証し、開発パターンを確立する。
    - **拡張性**: `work_type` で確立したアーキテクチャやコンポーネント（Adapter, Repositoryなど）は、将来的に他のマスタへ機能を拡張する際の基盤となり、効率的な横展開が可能になる。